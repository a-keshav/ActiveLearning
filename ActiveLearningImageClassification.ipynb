{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\anand\\anaconda3\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\anand\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\anand\\anaconda3\\lib\\site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\anand\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\anand\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\anand\\anaconda3\\lib\\site-packages (from torch) (2023.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\anand\\appdata\\roaming\\python\\python311\\site-packages (0.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\anand\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: requests in c:\\users\\anand\\anaconda3\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: torch==2.1.0 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from torchvision) (2.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\anand\\anaconda3\\lib\\site-packages (from torch==2.1.0->torchvision) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\anand\\anaconda3\\lib\\site-packages (from torch==2.1.0->torchvision) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\anand\\anaconda3\\lib\\site-packages (from torch==2.1.0->torchvision) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\anand\\anaconda3\\lib\\site-packages (from torch==2.1.0->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from torch==2.1.0->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\anand\\anaconda3\\lib\\site-packages (from torch==2.1.0->torchvision) (2023.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from jinja2->torch==2.1.0->torchvision) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from sympy->torch==2.1.0->torchvision) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcudnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcudnn\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Variable\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import math\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... unsuccessful initial attempt using frozen solve. Retrying with flexible solve.\n",
      "Solving environment: ...working... unsuccessful attempt using repodata from current_repodata.json, retrying with next repodata source.\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... unsuccessful initial attempt using frozen solve. Retrying with flexible solve.\n",
      "Solving environment: ...working... \n",
      "Found conflicts! Looking for incompatible packages.\n",
      "This can take several minutes.  Press CTRL-C to abort.\n",
      "failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): conda.anaconda.org:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): conda.anaconda.org:443\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/noarch/current_repodata.json HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/noarch/current_repodata.json HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/win-64/current_repodata.json HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/win-64/current_repodata.json HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/msys2/win-64/current_repodata.json HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://conda.anaconda.org:443 \"GET /pytorch/noarch/current_repodata.json HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/msys2/noarch/current_repodata.json HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://conda.anaconda.org:443 \"GET /pytorch/win-64/current_repodata.json HTTP/1.1\" 200 None\n",
      "\n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/win-64::aiobotocore==2.4.2=py311haa95532_0\n",
      "  - defaults/noarch::aioitertools==0.7.1=pyhd3eb1b0_0\n",
      "  - defaults/win-64::anaconda-navigator==2.4.2=py311haa95532_0\n",
      "  - defaults/noarch::argon2-cffi==21.3.0=pyhd3eb1b0_0\n",
      "  - defaults/noarch::conda-content-trust==0.1.1=pyhd3eb1b0_0\n",
      "  - defaults/noarch::conda-token==0.4.0=pyhd3eb1b0_0\n",
      "  - defaults/win-64::holoviews==1.17.0=py311haa95532_0\n",
      "  - defaults/win-64::hvplot==0.8.4=py311haa95532_0\n",
      "  - defaults/win-64::jupyter==1.0.0=py311haa95532_8\n",
      "  - defaults/win-64::jupyterlab==3.6.3=py311haa95532_0\n",
      "  - defaults/win-64::jupyterlab_server==2.22.0=py311haa95532_0\n",
      "  - defaults/win-64::jupyter_server==1.23.4=py311haa95532_0\n",
      "  - defaults/win-64::jupyter_server_fileid==0.9.0=py311haa95532_0\n",
      "  - defaults/win-64::jupyter_server_ydoc==0.8.0=py311haa95532_1\n",
      "  - defaults/win-64::nbclassic==0.5.5=py311haa95532_0\n",
      "  - defaults/win-64::notebook==6.5.4=py311haa95532_1\n",
      "  - defaults/win-64::notebook-shim==0.2.2=py311haa95532_0\n",
      "  - defaults/win-64::panel==1.2.1=py311haa95532_0\n",
      "  - defaults/win-64::s3fs==2023.3.0=py311haa95532_0\n",
      "  - defaults/win-64::scrapy==2.8.0=py311haa95532_0\n",
      "  - defaults/win-64::twisted==22.10.0=py311h2bbff1b_0\n",
      "  - defaults/win-64::typing-extensions==4.7.1=py311haa95532_0\n",
      "  - defaults/win-64::_anaconda_depends==2023.07=py311_1\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): conda.anaconda.org:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): conda.anaconda.org:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/noarch/repodata.json HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/msys2/win-64/repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://conda.anaconda.org:443 \"GET /pytorch/noarch/repodata.json HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/msys2/noarch/repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/noarch/repodata.json HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://conda.anaconda.org:443 \"GET /pytorch/win-64/repodata.json HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/win-64/repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/win-64/repodata.json HTTP/1.1\" 200 None\n",
      "\n",
      "Building graph of deps:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Examining pytorch-cpu:   0%|          | 0/5 [00:00<?, ?it/s] \n",
      "Examining @/win-64::__win==0=0:  20%|##        | 1/5 [00:02<00:08,  2.01s/it]\n",
      "Examining @/win-64::__win==0=0:  40%|####      | 2/5 [00:02<00:03,  1.00s/it]\n",
      "Examining @/win-64::__archspec==1=x86_64:  40%|####      | 2/5 [00:02<00:03,  1.00s/it]\n",
      "Examining @/win-64::__cuda==11.7=0:  60%|######    | 3/5 [00:02<00:02,  1.00s/it]      \n",
      "Examining python=3.11:  80%|########  | 4/5 [00:02<00:01,  1.00s/it]             \n",
      "                                                                    \n",
      "\n",
      "Determining conflicts:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Examining conflict for pytorch-cpu python:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "                                                                                \n",
      "\n",
      "UnsatisfiableError: The following specifications were found\n",
      "to be incompatible with the existing python installation in your environment:\n",
      "\n",
      "Specifications:\n",
      "\n",
      "  - pytorch-cpu -> python[version='>=3.5,<3.6.0a0|>=3.6,<3.7.0a0|>=3.7,<3.8.0a0']\n",
      "\n",
      "Your python: python=3.11\n",
      "\n",
      "If python is on the left-most side of the chain, that's the version you've asked for.\n",
      "When python appears to the right, that indicates that the thing on the left is somehow\n",
      "not available for the python version you are constrained to. Note that conda will not\n",
      "change your python version to a different minor version unless you explicitly specify\n",
      "that.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\anand\\appdata\\roaming\\python\\python311\\site-packages (0.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\anand\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: requests in c:\\users\\anand\\anaconda3\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: torch==2.1.0 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from torchvision) (2.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\anand\\anaconda3\\lib\\site-packages (from torch==2.1.0->torchvision) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\anand\\anaconda3\\lib\\site-packages (from torch==2.1.0->torchvision) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\anand\\anaconda3\\lib\\site-packages (from torch==2.1.0->torchvision) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\anand\\anaconda3\\lib\\site-packages (from torch==2.1.0->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from torch==2.1.0->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\anand\\anaconda3\\lib\\site-packages (from torch==2.1.0->torchvision) (2023.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from jinja2->torch==2.1.0->torchvision) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\anand\\anaconda3\\lib\\site-packages (from sympy->torch==2.1.0->torchvision) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!conda install pytorch-cpu -c pytorch \n",
    "!pip install torchvision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64 \n",
    "print(\"batch size\", BATCH_SIZE)\n",
    "LEARNING_RATE = 0.003\n",
    "TRAIN_DATA_PATH = \"categories_fruits_big/train/\"\n",
    "TEST_DATA_PATH = \"categories_fruits_big/test/\"\n",
    "# TRANSFORM_IMG = transforms.Compose([\n",
    "#     transforms.Resize(256),\n",
    "#     transforms.CenterCrop(256),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                          std=[0.229, 0.224, 0.225] )\n",
    "#     ])\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# transform_test = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(root=TRAIN_DATA_PATH, transform=transform_train)\n",
    "train_data_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True,  num_workers=4)\n",
    "test_data = torchvision.datasets.ImageFolder(root=TEST_DATA_PATH, transform=transform_test)\n",
    "test_data_loader  = data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4) \n",
    "\n",
    "trainset = train_data\n",
    "trainloader = train_data_loader\n",
    "testset = test_data\n",
    "testloader = test_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of train samples: \", len(train_data))\n",
    "print(\"Number of test samples: \", len(test_data))\n",
    "print(\"Detected Classes are: \", train_data.class_to_idx) # classes are detected by folder structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"num classes = \", len(train_data.class_to_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net3, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 28, 3,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(28)\n",
    "        self.conv2 = nn.Conv2d(28, 35, 3,padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(35)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.drop1 = nn.Dropout(p=0.2)\n",
    "        self.conv3 = nn.Conv2d(35, 16, 3,padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(16)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 8 * 8, 100)\n",
    "        self.drop2 = nn.Dropout(p=0.3)\n",
    "        self.fc2 = nn.Linear(100, 30)\n",
    "        self.bn4 = nn.BatchNorm1d(30)\n",
    "        self.fc3 = nn.Linear(30, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(F.relu(self.conv1(x)))\n",
    "        x = self.drop1(x)\n",
    "        x = self.bn2(F.relu(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.bn3(F.relu(self.conv3(x)))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 16 * 8 * 8)\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop2(x)\n",
    "        x = self.bn4(F.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "    \n",
    "        return F.log_softmax(x, dim=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating Active Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Model: Minimum Largest Difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot with Test Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_test_acc(model, testloader):\n",
    "    # Test the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        count = 0\n",
    "        for images, labels in testloader:\n",
    "            count += 1\n",
    "            images = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return (correct / total)\n",
    "\n",
    "def compute_train_acc(model, trainloader):\n",
    "    # Test the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        count = 0\n",
    "        for images, labels in trainloader:\n",
    "            count += 1\n",
    "            images = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return (correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal_batch\n",
    "def uncertainty_metric_max_min_difference_selection(model, trainloader):\n",
    "    batch_evaluation = []\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        outputs = model(images)\n",
    "        batch_differences = []\n",
    "        for j in range(len(outputs)):\n",
    "            min_prob = min(outputs[j])\n",
    "            max_prob = max(outputs[j])\n",
    "            diff = float(max_prob - min_prob)\n",
    "            batch_differences.append(diff)\n",
    "        batch_mean = np.mean(batch_differences)\n",
    "        batch_evaluation.append(batch_mean)\n",
    "    batch_evaluation = np.array(batch_evaluation)\n",
    "    k = 20\n",
    "#     largest = list((-batch_evaluation).argsort()[:k])\n",
    "    smallest = list(np.argsort(batch_evaluation)[:k])\n",
    "    return smallest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = []\n",
    "acc_list = []\n",
    "train_err_list = []\n",
    "test_err_list = []\n",
    "\n",
    "for trial in range(3):\n",
    "    active_model = Net3()\n",
    "    free_params = sum(p.numel() for p in active_model.parameters() if p.requires_grad)\n",
    "    print(free_params)\n",
    "\n",
    "    trainstep = 125\n",
    "    # Loss and optimizer\n",
    "\n",
    "    criterion = nn.NLLLoss() #You can modify the loss function\n",
    "    optimizer = optim.SGD(active_model.parameters(), lr=0.005, momentum=0.9, weight_decay=8e-4) #You can change the optimizer\n",
    "\n",
    "    # Train the model\n",
    "\n",
    "    total_step = len(trainloader)\n",
    "    print(total_step)\n",
    "    trial_loss_list = []\n",
    "    trial_acc_list = []\n",
    "\n",
    "    trial_train_err_list = []\n",
    "    trial_test_err_list = []\n",
    "\n",
    "    num_epochs = 200\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"epoch: \", epoch)\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        randomly_selected = uncertainty_metric_max_min_difference_selection(active_model, trainloader)\n",
    "        for i, (images, labels) in enumerate(trainloader):\n",
    "            if i not in randomly_selected:\n",
    "                continue\n",
    "\n",
    "    #         images = images.cuda(async=True)\n",
    "    #         labels = labels.cuda(async=True)\n",
    "\n",
    "            images = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "            # Run the forward pass\n",
    "    #         print(\"running forward pass....\")\n",
    "            outputs = active_model(images)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            trial_loss_list.append(loss.item())\n",
    "\n",
    "            # Backprop \n",
    "    #         print(\"backpropagating......\")\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "             # Track the accuracy\n",
    "            total = labels.size(0) + total\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct = (predicted == labels).sum().item() + correct\n",
    "            trial_acc_list.append(correct / total)\n",
    "\n",
    "\n",
    "            if (i + 1) % trainstep == 0:\n",
    "                w = torch.nn.utils.parameters_to_vector(active_model.parameters())\n",
    "                print(w)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                              (correct / total) * 100))\n",
    "        trial_train_err_list.append(compute_train_acc(active_model, trainloader))\n",
    "        trial_test_err_list.append(compute_test_acc(active_model, testloader))\n",
    "        if (total == correct):\n",
    "            break \n",
    "\n",
    "#     loss_list.append(np.array(trial_loss_list))\n",
    "#     acc_list.append(trial_acc_list)\n",
    "    train_err_list.append(trial_train_err_list)\n",
    "    test_err_list.append(trial_test_err_list)\n",
    "            \n",
    "print('Finished Training') \n",
    "\n",
    "# loss_list = np.array(loss_list)\n",
    "# acc_list = np.array(acc_list)\n",
    "train_err_list= np.array(train_err_list)\n",
    "test_err_list=np.array(test_err_list)\n",
    "\n",
    "# loss_list = np.mean(loss_list, axis=0)\n",
    "# acc_list = np.mean(acc_list, axis=0)\n",
    "train_err_list= np.mean(train_err_list, axis=0)\n",
    "test_err_list=np.mean(test_err_list, axis=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing = []\n",
    "# testing.append([1,2,3])\n",
    "# testing.append([4,2,3])\n",
    "# testing = np.array(testing)\n",
    "# print(np.mean(testing, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... after training, save your model \n",
    "model_filename = 'res_test2/active_model3_minimum.pt'\n",
    "torch.save(active_model.state_dict(), model_filename)\n",
    "\n",
    "# .. to load your previously training model:\n",
    "# model2 = Net3()\n",
    "# model2.load_state_dict(torch.load(model_filename))\n",
    "# model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_train_err_list = train_err_list\n",
    "active_test_err_list = test_err_list\n",
    "active_acc_list1 = acc_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"res_test2/test1_largest_margin_minimum_training_accuracy.pickle\",\"wb\")\n",
    "pickle.dump(active_train_err_list, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "\n",
    "pickle_out = open(\"res_test2/test1_largest_margin_minimum_testing_accuracy.pickle\",\"wb\")\n",
    "pickle.dump(active_test_err_list, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "# pickle_out = open(\"test1_random_testing_accuracy.pickle\",\"wb\")\n",
    "# pickle.dump(new_rand_test_err_list, pickle_out)\n",
    "# pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_model2 = Net3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_loss_list = []\n",
    "rand_acc_list = []\n",
    "rand_train_err_list = []\n",
    "rand_test_err_list = []\n",
    "\n",
    "for trial in range(3):\n",
    "    random_model2 = Net3()\n",
    "    free_params = sum(p.numel() for p in random_model2.parameters() if p.requires_grad)\n",
    "\n",
    "    trainstep = 125\n",
    "    # Loss and optimizer\n",
    "\n",
    "    criterion = nn.NLLLoss() #You can modify the loss function\n",
    "    optimizer = optim.SGD(random_model2.parameters(), lr=0.005, momentum=0.9, weight_decay=8e-4) #You can change the optimizer\n",
    "\n",
    "    # Train the model\n",
    "\n",
    "    total_step = len(trainloader)\n",
    "    print(total_step)\n",
    "    trial_rand_loss_list = []\n",
    "    trial_rand_acc_list = []\n",
    "\n",
    "    trial_rand_train_err_list = []\n",
    "    trial_rand_test_err_list = []\n",
    "\n",
    "    num_epochs = 200\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"epoch: \", epoch)\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        randomly_selected = np.random.choice(range(len(list(trainloader))), size=20)\n",
    "        for i, (images, labels) in enumerate(trainloader):\n",
    "            if i not in randomly_selected:\n",
    "                continue\n",
    "\n",
    "    #         images = images.cuda(async=True)\n",
    "    #         labels = labels.cuda(async=True)\n",
    "\n",
    "            images = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "            # Run the forward pass\n",
    "    #         print(\"running forward pass....\")\n",
    "            outputs = random_model2(images)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            rand_loss_list.append(loss.item())\n",
    "\n",
    "            # Backprop \n",
    "    #         print(\"backpropagating......\")\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "             # Track the accuracy\n",
    "            total = labels.size(0) + total\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct = (predicted == labels).sum().item() + correct\n",
    "            rand_acc_list.append(correct / total)\n",
    "\n",
    "\n",
    "            if (i + 1) % trainstep == 0:\n",
    "                w = torch.nn.utils.parameters_to_vector(random_model2.parameters())\n",
    "                print(w)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                              (correct / total) * 100))\n",
    "        trial_rand_train_err_list.append(compute_train_acc(random_model2, trainloader))\n",
    "        trial_rand_test_err_list.append(compute_test_acc(random_model2, testloader))\n",
    "        if (total == correct):\n",
    "            break \n",
    "\n",
    "    rand_loss_list.append(trial_rand_loss_list)\n",
    "    rand_acc_list.append(trial_rand_acc_list)\n",
    "    rand_train_err_list.append(trial_rand_train_err_list)\n",
    "    rand_test_err_list.append(trial_rand_test_err_list)\n",
    "            \n",
    "print('Finished Training') \n",
    "\n",
    "# rand_loss_list = np.array(rand_loss_list)\n",
    "# rand_acc_list = np.array(rand_acc_list)\n",
    "rand_train_err_list= np.array(rand_train_err_list)\n",
    "rand_test_err_list=np.array(rand_test_err_list)\n",
    "\n",
    "# rand_loss_list = np.mean(rand_loss_list, axis=0)\n",
    "# rand_acc_list = np.mean(rand_acc_list, axis=0)\n",
    "rand_train_err_list= np.mean(rand_train_err_list, axis=0)\n",
    "rand_test_err_list=np.mean(rand_test_err_list, axis=0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Largest Margin to Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_active_train_err_list = [0]\n",
    "new_active_train_err_list.extend(active_train_err_list)\n",
    "plt.plot(new_active_train_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "new_rand_train_err_list = [0]\n",
    "new_rand_train_err_list.extend(rand_train_err_list)\n",
    "plt.plot(new_rand_train_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.legend(['active', 'random'])\n",
    "plt.title(\"Active Training Set Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Set Accuracy\")\n",
    "plt.savefig(\"res_test2/test3_4_acc1.png\")\n",
    "plt.show()\n",
    "\n",
    "pickle_out = open(\"res_test2/test1_largest_margin_minimum2_training_accuracy.pickle\",\"wb\")\n",
    "pickle.dump(new_active_train_err_list, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"res_test2/test1_random2_training_accuracy.pickle\",\"wb\")\n",
    "pickle.dump(new_rand_train_err_list, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_active_test_err_list = [0]\n",
    "new_active_test_err_list.extend(active_test_err_list)\n",
    "\n",
    "# plt.plot(new_second_train_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "new_rand_test_err_list = [0]\n",
    "new_rand_test_err_list.extend(rand_test_err_list)\n",
    "\n",
    "plt.plot(new_active_test_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.plot(new_rand_test_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.legend(['active', 'random'])\n",
    "plt.title(\"Active Test Set Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Test Set Accuracy\")\n",
    "plt.savefig(\"res_test2/test3_4_acc2.png\")\n",
    "plt.show()\n",
    "\n",
    "pickle_out = open(\"res_test2/test2_largest_margin_minimum2_testing_accuracy.pickle\",\"wb\")\n",
    "pickle.dump(new_active_test_err_list, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"res_test2/test2_random2_testing_accuracy.pickle\",\"wb\")\n",
    "pickle.dump(new_rand_test_err_list, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... after training, save your model \n",
    "model_filename = 'res_test2/random_model2.pt'\n",
    "torch.save(random_model2.state_dict(), model_filename)\n",
    "\n",
    "# .. to load your previously training model:\n",
    "# model2 = Net3()\n",
    "# model2.load_state_dict(torch.load(model_filename))\n",
    "# model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(active_train_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.plot(rand_train_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.legend(['active', 'random'])\n",
    "plt.title(\"Active Training Set Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Set Accuracy\")\n",
    "plt.savefig(\"res_test2/test2_acc1_min.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(active_test_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.plot(rand_test_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.legend(['active', 'random'])\n",
    "plt.title(\"Active Training Set Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Set Accuracy\")\n",
    "plt.savefig(\"res_test2/test2_acc2_min.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second_model1 = Net3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal_batch\n",
    "def uncertainty_metric_max_second_difference_selection(model, trainloader):\n",
    "    batch_evaluation = []\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        outputs = model(images)\n",
    "        batch_differences = []\n",
    "        for j in range(len(outputs)):\n",
    "            \n",
    "#             min_prob = min(outputs[j])\n",
    "            vals = outputs[j].data.numpy()\n",
    "            top_two = vals[np.argsort(vals)[-2:]]\n",
    "            \n",
    "            diff = abs(float(top_two[0] - top_two[1]))\n",
    "            batch_differences.append(diff)\n",
    "        batch_mean = np.mean(batch_differences)\n",
    "        batch_evaluation.append(batch_mean)\n",
    "    batch_evaluation = np.array(batch_evaluation)\n",
    "    k = 20\n",
    "#     largest = list((-batch_evaluation).argsort()[:k])\n",
    "    smallest = list(np.argsort(batch_evaluation)[:k])\n",
    "    return smallest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_loss_list = []\n",
    "second_acc_list = []\n",
    "second_train_err_list = []\n",
    "second_test_err_list = []\n",
    "\n",
    "for trial in range(3):\n",
    "    second_model1 = Net3()\n",
    "    free_params = sum(p.numel() for p in second_model1.parameters() if p.requires_grad)\n",
    "# print(free_params)\n",
    "\n",
    "    trainstep = 125\n",
    "    # Loss and optimizer\n",
    "\n",
    "    criterion = nn.NLLLoss() #You can modify the loss function\n",
    "    optimizer = optim.SGD(second_model1.parameters(), lr=0.005, momentum=0.9, weight_decay=8e-4) #You can change the optimizer\n",
    "\n",
    "    # Train the model\n",
    "\n",
    "    total_step = len(trainloader)\n",
    "    print(total_step)\n",
    "    trial_second_loss_list = []\n",
    "    trial_second_acc_list = []\n",
    "\n",
    "    trial_second_train_err_list = []\n",
    "    trial_second_test_err_list = []\n",
    "\n",
    "    num_epochs = 200\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"epoch: \", epoch)\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        randomly_selected = uncertainty_metric_max_second_difference_selection(second_model1, trainloader)\n",
    "        for i, (images, labels) in enumerate(trainloader):\n",
    "            if i not in randomly_selected:\n",
    "                continue\n",
    "\n",
    "    #         images = images.cuda(async=True)\n",
    "    #         labels = labels.cuda(async=True)\n",
    "\n",
    "            images = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "            # Run the forward pass\n",
    "    #         print(\"running forward pass....\")\n",
    "            outputs = second_model1(images)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            trial_second_loss_list.append(loss.item())\n",
    "\n",
    "            # Backprop \n",
    "    #         print(\"backpropagating......\")\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "             # Track the accuracy\n",
    "            total = labels.size(0) + total\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct = (predicted == labels).sum().item() + correct\n",
    "            trial_second_acc_list.append(correct / total)\n",
    "\n",
    "\n",
    "            if (i + 1) % trainstep == 0:\n",
    "                w = torch.nn.utils.parameters_to_vector(second_model1.parameters())\n",
    "                print(w)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                              (correct / total) * 100))\n",
    "        trial_second_train_err_list.append(compute_train_acc(second_model1, trainloader))\n",
    "        trial_second_test_err_list.append(compute_test_acc(second_model1, testloader))\n",
    "        if (total == correct):\n",
    "            break \n",
    "\n",
    "    second_loss_list.append(trial_second_loss_list)\n",
    "    second_acc_list.append(trial_second_acc_list)\n",
    "    second_train_err_list.append(trial_second_train_err_list)\n",
    "    second_test_err_list.append(trial_second_test_err_list)\n",
    "            \n",
    "print('Finished Training') \n",
    "\n",
    "second_loss_list = np.array(second_loss_list)\n",
    "second_acc_list = np.array(second_acc_list)\n",
    "second_train_err_list= np.array(second_train_err_list)\n",
    "second_test_err_list=np.array(second_test_err_list)\n",
    "\n",
    "second_loss_list = np.mean(second_loss_list, axis=0)\n",
    "second_acc_list = np.mean(second_acc_list, axis=0)\n",
    "second_train_err_list= np.mean(second_train_err_list, axis=0)\n",
    "second_test_err_list=np.mean(second_test_err_list, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... after training, save your model \n",
    "model_filename = 'res_test2/second_model3_small.pt'\n",
    "torch.save(second_model1.state_dict(), model_filename)\n",
    "\n",
    "# .. to load your previously training model:\n",
    "# model2 = Net3()\n",
    "# model2.load_state_dict(torch.load(model_filename))\n",
    "# model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_second_train_err_list = [0]\n",
    "new_second_train_err_list.extend(second_train_err_list)\n",
    "plt.plot(new_second_train_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "new_rand_train_err_list = [0]\n",
    "new_rand_train_err_list.extend(rand_train_err_list)\n",
    "plt.plot(new_rand_train_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.legend(['active', 'random'])\n",
    "plt.title(\"Active Training Set Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Set Accuracy\")\n",
    "plt.savefig(\"res_test2/test2_4_acc1.png\")\n",
    "plt.show()\n",
    "\n",
    "pickle_out = open(\"res_test2/test1_smallest_margin_minimum_training_accuracy.pickle\",\"wb\")\n",
    "pickle.dump(new_second_train_err_list, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"res_test2/test1_random_training_accuracy.pickle\",\"wb\")\n",
    "pickle.dump(new_rand_train_err_list, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_second_test_err_list = [0]\n",
    "new_second_test_err_list.extend(second_test_err_list)\n",
    "\n",
    "# plt.plot(new_second_train_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "new_rand_test_err_list = [0]\n",
    "new_rand_test_err_list.extend(rand_test_err_list)\n",
    "\n",
    "plt.plot(new_second_test_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.plot(new_rand_test_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.legend(['active', 'random'])\n",
    "plt.title(\"Active Test Set Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Test Set Accuracy\")\n",
    "plt.savefig(\"res_test2/test2_4_acc2.png\")\n",
    "plt.show()\n",
    "\n",
    "pickle_out = open(\"res_test2/test1_smallest_margin_minimum_testing_accuracy.pickle\",\"wb\")\n",
    "pickle.dump(new_second_test_err_list, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"res_test2/test1_random_testing_accuracy.pickle\",\"wb\")\n",
    "pickle.dump(new_rand_test_err_list, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(second_test_err_list)\n",
    "plt.plot(active_test_err_list)\n",
    "# plt.plot(rand_test_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.legend(['smallest margin', 'largest margin', 'random'])\n",
    "plt.title(\"Active Test Set Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Test Set Accuracy\")\n",
    "plt.savefig(\"res_test2/test2_acc2.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Active, Second, Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_active_train_err_list = [0]\n",
    "new_active_train_err_list.extend(active_train_err_list)\n",
    "plt.plot(new_active_train_err_list)\n",
    "\n",
    "new_second_train_err_list = [0]\n",
    "new_second_train_err_list.extend(second_train_err_list)\n",
    "plt.plot(new_second_train_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "new_rand_train_err_list = [0]\n",
    "new_rand_train_err_list.extend(rand_train_err_list)\n",
    "plt.plot(new_rand_train_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.legend(['largest margin', 'smallest margin', 'random'])\n",
    "plt.title(\"Active Training Set Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Set Accuracy\")\n",
    "plt.savefig(\"res_test2/comparisontest2_4_acc1.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "pickle_out = open(\"res_test2/test2_largest_margin_minimum_training_accuracy.pickle\",\"wb\")\n",
    "pickle.dump(new_active_train_err_list, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "\n",
    "pickle_out = open(\"res_test2/test2_smallest_margin_minimum_training_accuracy.pickle\",\"wb\")\n",
    "pickle.dump(new_second_train_err_list, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"res_test2/test2_random_training_accuracy.pickle\",\"wb\")\n",
    "pickle.dump(new_rand_train_err_list, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_active_test_err_list = [0]\n",
    "new_active_test_err_list.extend(active_test_err_list)\n",
    "\n",
    "new_second_test_err_list = [0]\n",
    "new_second_test_err_list.extend(second_test_err_list)\n",
    "\n",
    "# plt.plot(new_second_train_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "new_rand_test_err_list = [0]\n",
    "new_rand_test_err_list.extend(rand_test_err_list)\n",
    "\n",
    "plt.plot(new_active_test_err_list)\n",
    "\n",
    "plt.plot(new_second_test_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.plot(new_rand_test_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.legend(['largest margin', 'smallest margin', 'random'])\n",
    "plt.title(\"Active Test Set Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Test Set Accuracy\")\n",
    "plt.savefig(\"res_test2/comparisontest2_4_acc2.png\")\n",
    "plt.show()\n",
    "\n",
    "pickle_out = open(\"res_test2/test2_largest_margin_minimum_testing_accuracy.pickle\",\"wb\")\n",
    "pickle.dump(new_active_test_err_list, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"res_test2/test2_smallest_margin_minimum_testing_accuracy.pickle\",\"wb\")\n",
    "pickle.dump(new_second_test_err_list, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"res_test2/test2_random_testing_accuracy.pickle\",\"wb\")\n",
    "pickle.dump(new_rand_test_err_list, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entropy_model1 = Net3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal_batch\n",
    "def uncertainty_metric_entropy_selection(model, trainloader):\n",
    "    batch_evaluation = []\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        outputs = model(images)\n",
    "        batch_differences = []\n",
    "        for j in range(len(outputs)):\n",
    "            total = 0\n",
    "            output_probs = outputs[j].data.numpy()\n",
    "            for item in output_probs:\n",
    "                entropy = -1* item * np.log(item)\n",
    "                total += entropy\n",
    "            batch_differences.append(total)\n",
    "            \n",
    "        batch_mean = np.mean(batch_differences)\n",
    "        batch_evaluation.append(batch_mean)\n",
    "    batch_evaluation = np.array(batch_evaluation)\n",
    "    k = 20\n",
    "    largest = list((-batch_evaluation).argsort()[:k])\n",
    "#     smallest = list(np.argsort(batch_evaluation)[:k])\n",
    "    return largest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_loss_list = []\n",
    "entropy_acc_list = []\n",
    "entropy_train_err_list = []\n",
    "entropy_test_err_list = []\n",
    "\n",
    "for trial in range(3):\n",
    "    entropy_model1 = Net3()\n",
    "    free_params = sum(p.numel() for p in entropy_model1.parameters() if p.requires_grad)\n",
    "    print(free_params)\n",
    "\n",
    "    trainstep = 125\n",
    "    # Loss and optimizer\n",
    "\n",
    "    criterion = nn.NLLLoss() #You can modify the loss function\n",
    "    optimizer = optim.SGD(entropy_model1.parameters(), lr=0.005, momentum=0.9, weight_decay=8e-4) #You can change the optimizer\n",
    "\n",
    "    # Train the model\n",
    "\n",
    "    total_step = len(trainloader)\n",
    "    print(total_step)\n",
    "    trial_entropy_loss_list = []\n",
    "    trial_entropy_acc_list = []\n",
    "\n",
    "    trial_entropy_train_err_list = []\n",
    "    trial_entropy_test_err_list = []\n",
    "\n",
    "    num_epochs = 200\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"epoch: \", epoch)\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        randomly_selected = uncertainty_metric_entropy_selection(entropy_model1, trainloader)\n",
    "        for i, (images, labels) in enumerate(trainloader):\n",
    "            if i not in randomly_selected:\n",
    "                continue\n",
    "\n",
    "    #         images = images.cuda(async=True)\n",
    "    #         labels = labels.cuda(async=True)\n",
    "\n",
    "            images = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "            # Run the forward pass\n",
    "    #         print(\"running forward pass....\")\n",
    "            outputs = entropy_model1(images)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            trial_entropy_loss_list.append(loss.item())\n",
    "\n",
    "            # Backprop \n",
    "    #         print(\"backpropagating......\")\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "             # Track the accuracy\n",
    "            total = labels.size(0) + total\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct = (predicted == labels).sum().item() + correct\n",
    "            trial_entropy_acc_list.append(correct / total)\n",
    "\n",
    "\n",
    "            if (i + 1) % trainstep == 0:\n",
    "                w = torch.nn.utils.parameters_to_vector(entropy_model1.parameters())\n",
    "                print(w)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                              (correct / total) * 100))\n",
    "        trial_entropy_train_err_list.append(compute_train_acc(entropy_model1, trainloader))\n",
    "        trial_entropy_test_err_list.append(compute_test_acc(entropy_model1, testloader))\n",
    "        if (total == correct):\n",
    "            break \n",
    "\n",
    "    entropy_loss_list.append(trial_entropy_loss_list)\n",
    "    entropy_acc_list.append(trial_entropy_acc_list)\n",
    "    entropy_train_err_list.append(trial_entropy_train_err_list)\n",
    "    entropy_test_err_list.append(trial_entropy_test_err_list)\n",
    "            \n",
    "print('Finished Training') \n",
    "\n",
    "entropy_loss_list = np.array(entropy_loss_list)\n",
    "entropy_acc_list = np.array(entropy_acc_list)\n",
    "entropy_train_err_list= np.array(entropy_train_err_list)\n",
    "entropy_test_err_list=np.array(entropy_test_err_list)\n",
    "\n",
    "entropy_loss_list = np.mean(entropy_loss_list, axis=0)\n",
    "entropy_acc_list = np.mean(entropy_acc_list, axis=0)\n",
    "entropy_train_err_list= np.mean(entropy_train_err_list, axis=0)\n",
    "entropy_test_err_list=np.mean(entropy_test_err_list, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... after training, save your model \n",
    "model_filename = 'res_test2/entropy_model1.pt'\n",
    "torch.save(entropy_model1.state_dict(), model_filename)\n",
    "\n",
    "# .. to load your previously training model:\n",
    "# model2 = Net3()\n",
    "# model2.load_state_dict(torch.load(model_filename))\n",
    "# model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(entropy_train_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.plot(rand_train_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.legend(['active', 'random'])\n",
    "plt.title(\"Active Training Set Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Set Accuracy\")\n",
    "plt.savefig(\"res_test2/test3_acc1.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(entropy_test_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.plot(rand_test_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.legend(['active', 'random'])\n",
    "plt.title(\"Active Test Set Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Test Set Accuracy\")\n",
    "plt.savefig(\"res_test2/test3_acc2.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_entropy_train_err_list = [0]\n",
    "new_entropy_train_err_list.extend(entropy_train_err_list)\n",
    "plt.plot(new_entropy_train_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "new_rand_train_err_list = [0]\n",
    "new_rand_train_err_list.extend(rand_train_err_list)\n",
    "plt.plot(new_rand_train_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.legend(['active', 'random'])\n",
    "plt.title(\"Active Training Set Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Set Accuracy\")\n",
    "plt.savefig(\"res_test2/test3_4_acc1.png\")\n",
    "plt.show()\n",
    "\n",
    "pickle_out = open(\"res_test2/test1_entropy_maxmimum_training_accuracy.pickle\",\"wb\")\n",
    "pickle.dump(new_entropy_train_err_list, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "# pickle_out = open(\"test1_random_training_accuracy.pickle\",\"wb\")\n",
    "# pickle.dump(new_rand_train_err_list, pickle_out)\n",
    "# pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_entropy_test_err_list = [0]\n",
    "new_entropy_test_err_list.extend(entropy_test_err_list)\n",
    "\n",
    "# plt.plot(new_second_train_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "new_rand_test_err_list = [0]\n",
    "new_rand_test_err_list.extend(rand_test_err_list)\n",
    "\n",
    "plt.plot(new_entropy_test_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.plot(new_rand_test_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.legend(['active', 'random'])\n",
    "plt.title(\"Active Test Set Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Test Set Accuracy\")\n",
    "plt.savefig(\"res_test2/test3_4_acc2.png\")\n",
    "plt.show()\n",
    "\n",
    "pickle_out = open(\"res_test2/test1_entropy_maximum_testing_accuracy.pickle\",\"wb\")\n",
    "pickle.dump(new_entropy_test_err_list, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "# pickle_out = open(\"test1_random_testing_accuracy.pickle\",\"wb\")\n",
    "# pickle.dump(new_rand_test_err_list, pickle_out)\n",
    "# pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_active_train_err_list = [0]\n",
    "new_active_train_err_list.extend(active_train_err_list)\n",
    "plt.plot(new_active_train_err_list)\n",
    "\n",
    "new_second_train_err_list = [0]\n",
    "new_second_train_err_list.extend(second_train_err_list)\n",
    "plt.plot(new_second_train_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "new_rand_train_err_list = [0]\n",
    "new_rand_train_err_list.extend(rand_train_err_list)\n",
    "plt.plot(new_rand_train_err_list)\n",
    "\n",
    "new_entropy_train_err_list = [0]\n",
    "new_entropy_train_err_list.extend(entropy_train_err_list)\n",
    "plt.plot(new_entropy_train_err_list)\n",
    "\n",
    "\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.legend(['largest margin', 'smallest margin','entropy', 'random'])\n",
    "plt.title(\"Active Training Set Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Set Accuracy\")\n",
    "plt.savefig(\"res_test2/comparisontest2_6_acc1.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_active_test_err_list = [0]\n",
    "new_active_test_err_list.extend(active_test_err_list)\n",
    "\n",
    "new_second_test_err_list = [0]\n",
    "new_second_test_err_list.extend(second_test_err_list)\n",
    "\n",
    "# plt.plot(new_second_train_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "new_rand_test_err_list = [0]\n",
    "new_rand_test_err_list.extend(rand_test_err_list)\n",
    "\n",
    "plt.plot(new_active_test_err_list)\n",
    "\n",
    "plt.plot(new_second_test_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.plot(new_rand_test_err_list)\n",
    "\n",
    "new_entropy_test_err_list = [0]\n",
    "new_entropy_test_err_list.extend(entropy_test_err_list)\n",
    "plt.plot(new_entropy_test_err_list)\n",
    "\n",
    "\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.legend(['largest margin', 'smallest margin','entropy',  'random'])\n",
    "plt.title(\"Active Test Set Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Test Set Accuracy\")\n",
    "plt.savefig(\"res_test2/comparisontest2_6_acc2.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least Confident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lc_model1 = Net3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal_batch\n",
    "def uncertainty_metric_lc_selection(model, trainloader):\n",
    "    batch_evaluation = []\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        outputs = model(images)\n",
    "        batch_differences = []\n",
    "        for j in range(len(outputs)):\n",
    "            max_prob = max(outputs[j])\n",
    "            diff = float(1 - max_prob)\n",
    "            batch_differences.append(diff)\n",
    "        batch_mean = np.sum(batch_differences)\n",
    "        batch_evaluation.append(batch_mean)\n",
    "    batch_evaluation = np.array(batch_evaluation)\n",
    "    k = 20\n",
    "    return list((-batch_evaluation).argsort()[:k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_loss_list = []\n",
    "lc_acc_list = []\n",
    "lc_train_err_list = []\n",
    "lc_test_err_list = []\n",
    "\n",
    "for trial in range(3):\n",
    "    lc_model1 = Net3()\n",
    "    free_params = sum(p.numel() for p in lc_model1.parameters() if p.requires_grad)\n",
    "    print(free_params)\n",
    "\n",
    "    trainstep = 125\n",
    "    # Loss and optimizer\n",
    "\n",
    "    criterion = nn.NLLLoss() #You can modify the loss function\n",
    "    optimizer = optim.SGD(lc_model1.parameters(), lr=0.005, momentum=0.9, weight_decay=8e-4) #You can change the optimizer\n",
    "\n",
    "    # Train the model\n",
    "\n",
    "    total_step = len(trainloader)\n",
    "    print(total_step)\n",
    "    trial_lc_loss_list = []\n",
    "    trial_lc_acc_list = []\n",
    "\n",
    "    trial_lc_train_err_list = []\n",
    "    trial_lc_test_err_list = []\n",
    "\n",
    "    num_epochs = 200\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"epoch: \", epoch)\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        randomly_selected = uncertainty_metric_lc_selection(lc_model1, trainloader)\n",
    "        for i, (images, labels) in enumerate(trainloader):\n",
    "            if i not in randomly_selected:\n",
    "                continue\n",
    "\n",
    "    #         images = images.cuda(async=True)\n",
    "    #         labels = labels.cuda(async=True)\n",
    "\n",
    "            images = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "            # Run the forward pass\n",
    "    #         print(\"running forward pass....\")\n",
    "            outputs = lc_model1(images)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            trial_lc_loss_list.append(loss.item())\n",
    "\n",
    "            # Backprop \n",
    "    #         print(\"backpropagating......\")\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "             # Track the accuracy\n",
    "            total = labels.size(0) + total\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct = (predicted == labels).sum().item() + correct\n",
    "            trial_lc_acc_list.append(correct / total)\n",
    "\n",
    "\n",
    "            if (i + 1) % trainstep == 0:\n",
    "                w = torch.nn.utils.parameters_to_vector(lc_model1.parameters())\n",
    "                print(w)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                              (correct / total) * 100))\n",
    "        trial_lc_train_err_list.append(compute_train_acc(lc_model1, trainloader))\n",
    "        trial_lc_test_err_list.append(compute_test_acc(lc_model1, testloader))\n",
    "        if (total == correct):\n",
    "            break \n",
    "\n",
    "    lc_loss_list.append(trial_lc_loss_list)\n",
    "    lc_acc_list.append(trial_lc_acc_list)\n",
    "    lc_train_err_list.append(trial_lc_train_err_list)\n",
    "    lc_test_err_list.append(trial_lc_test_err_list)\n",
    "            \n",
    "print('Finished Training') \n",
    "\n",
    "lc_loss_list = np.array(lc_loss_list)\n",
    "lc_acc_list = np.array(lc_acc_list)\n",
    "lc_train_err_list= np.array(lc_train_err_list)\n",
    "lc_test_err_list=np.array(lc_test_err_list)\n",
    "\n",
    "lc_loss_list = np.mean(lc_loss_list, axis=0)\n",
    "lc_acc_list = np.mean(lc_acc_list, axis=0)\n",
    "lc_train_err_list= np.mean(lc_train_err_list, axis=0)\n",
    "lc_test_err_list=np.mean(lc_test_err_list, axis=0)\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... after training, save your model \n",
    "model_filename = 'res_test2/lc_model1.pt'\n",
    "torch.save(lc_model1.state_dict(), model_filename)\n",
    "\n",
    "# .. to load your previously training model:\n",
    "# model2 = Net3()\n",
    "# model2.load_state_dict(torch.load(model_filename))\n",
    "# model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lc_train_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.plot(rand_train_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.legend(['active', 'random'])\n",
    "plt.title(\"Active Training Set Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Set Accuracy\")\n",
    "plt.savefig(\"res_test2/test4_acc1.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lc_test_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.plot(rand_test_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.legend(['active', 'random'])\n",
    "plt.title(\"Active Test Set Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Test Set Accuracy\")\n",
    "plt.savefig(\"res_test2/test4_acc2.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lc_train_err_list = [0]\n",
    "new_lc_train_err_list.extend(lc_train_err_list)\n",
    "plt.plot(new_lc_train_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "new_rand_train_err_list = [0]\n",
    "new_rand_train_err_list.extend(rand_train_err_list)\n",
    "plt.plot(new_rand_train_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.legend(['active', 'random'])\n",
    "plt.title(\"Active Training Set Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Set Accuracy\")\n",
    "plt.savefig(\"res_test2/test4_4_acc1.png\")\n",
    "plt.show()\n",
    "\n",
    "pickle_out = open(\"res_test2/test1_lc_maxmimum_training_accuracy.pickle\",\"wb\")\n",
    "pickle.dump(new_entropy_train_err_list, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "# pickle_out = open(\"test1_random_training_accuracy.pickle\",\"wb\")\n",
    "# pickle.dump(new_rand_train_err_list, pickle_out)\n",
    "# pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lc_test_err_list = [0]\n",
    "new_lc_test_err_list.extend(lc_test_err_list)\n",
    "\n",
    "# plt.plot(new_second_train_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "new_rand_test_err_list = [0]\n",
    "new_rand_test_err_list.extend(rand_test_err_list)\n",
    "\n",
    "plt.plot(new_lc_test_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.plot(new_rand_test_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.legend(['active', 'random'])\n",
    "plt.title(\"Active Test Set Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Test Set Accuracy\")\n",
    "plt.savefig(\"res_test2/test4_4_acc2.png\")\n",
    "plt.show()\n",
    "\n",
    "pickle_out = open(\"res_test2/test1_lc_maximum_testing_accuracy.pickle\",\"wb\")\n",
    "pickle.dump(new_entropy_test_err_list, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "# pickle_out = open(\"test1_random_testing_accuracy.pickle\",\"wb\")\n",
    "# pickle.dump(new_rand_test_err_list, pickle_out)\n",
    "# pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_active_train_err_list = [0]\n",
    "new_active_train_err_list.extend(active_train_err_list)\n",
    "plt.plot(new_active_train_err_list)\n",
    "\n",
    "new_second_train_err_list = [0]\n",
    "new_second_train_err_list.extend(second_train_err_list)\n",
    "plt.plot(new_second_train_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "new_rand_train_err_list = [0]\n",
    "new_rand_train_err_list.extend(rand_train_err_list)\n",
    "plt.plot(new_rand_train_err_list)\n",
    "\n",
    "new_entropy_train_err_list = [0]\n",
    "new_entropy_train_err_list.extend(entropy_train_err_list)\n",
    "plt.plot(new_entropy_train_err_list)\n",
    "\n",
    "new_lc_train_err_list = [0]\n",
    "new_lc_train_err_list.extend(lc_train_err_list)\n",
    "plt.plot(new_lc_train_err_list)\n",
    "\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.legend(['largest margin', 'smallest margin','entropy', 'least-confidence', 'random'])\n",
    "plt.title(\"Active Training Set Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Set Accuracy\")\n",
    "plt.savefig(\"res_test2/comparisontest2_5_acc1.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_active_test_err_list = [0]\n",
    "new_active_test_err_list.extend(active_test_err_list)\n",
    "\n",
    "new_second_test_err_list = [0]\n",
    "new_second_test_err_list.extend(second_test_err_list)\n",
    "\n",
    "# plt.plot(new_second_train_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "new_rand_test_err_list = [0]\n",
    "new_rand_test_err_list.extend(rand_test_err_list)\n",
    "\n",
    "plt.plot(new_active_test_err_list)\n",
    "\n",
    "plt.plot(new_second_test_err_list)\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.plot(new_rand_test_err_list)\n",
    "\n",
    "new_entropy_test_err_list = [0]\n",
    "new_entropy_test_err_list.extend(entropy_test_err_list)\n",
    "plt.plot(new_entropy_test_err_list)\n",
    "\n",
    "new_lc_test_err_list = [0]\n",
    "new_lc_test_err_list.extend(lc_test_err_list)\n",
    "plt.plot(new_lc_test_err_list)\n",
    "\n",
    "# plt.plot(active_test_err_list)\n",
    "plt.legend(['largest margin', 'smallest margin','entropy', 'least-confidence', 'random'])\n",
    "plt.title(\"Active Test Set Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Test Set Accuracy\")\n",
    "plt.savefig(\"res_test2/comparisontest2_5_acc2.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
